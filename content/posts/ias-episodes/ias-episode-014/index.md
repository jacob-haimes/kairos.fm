---
title: LLMs, A Survey
summary: Take a trip with me through the paper "Large Language Models, A Survey".
date: 2024-02-26
lastmod: 2024-06-18

image:
  caption: 'Into AI Safety Cover Art'
  preview_only: true
  filename: ias_cover_art.jpeg

authors:
  - intoaisafety

tags:
  - Minisode
  - Paper Review
  - Survey

categories: 
  - Podcast
---

<div style="text-align: justify">
Take a trip with me through the paper <a href="https://arxiv.org/abs/2402.06196" target="_blank" rel="noreferrer noopener">Large Language Models, A Survey</a>, published on February 9th of 2024. All figures and tables mentioned throughout the episode can be found on the Into AI Safety podcast website.

{{< transistor src="https://share.transistor.fm/e/24982632" >}}
</div>

### Chapters

<div style="text-align: left; font-family:monospace;">
00:36 ❙ Intro and authors<br>
01:50 ❙ My takes and paper structure<br>
04:40 ❙ Getting to LLMs<br>
07:27 ❙ Defining LLMs & emergence<br>
12:12 ❙ Overview of PLMs<br>
15:00 ❙ How LLMs are built<br>
18:52 ❙ Limitations if LLMs<br>
23:06 ❙ Uses of LLMs<br>
25:16 ❙ Evaluations and Benchmarks<br>
28:11 ❙ Challenges and future directions<br>
29:21 ❙ Recap & outro
</div>

### Select Figures and Tables

{{< multi-image-quickview folder="llms-a-survey" >}}

### Links

Links to all articles/papers which are mentioned throughout the episode can be found below, in order of their appearance.
- <a href="https://arxiv.org/abs/2402.06196" target="_blank" rel="noreferrer noopener">Large Language Models, A Survey</a>
- <a href="https://www.linkedin.com/posts/meysam-ac_i-am-delighted-to-share-that-our-most-recent-activity-7162768857827377152-wiLu/?utm_source=share&utm_medium=member_desktop" target="_blank" rel="noreferrer noopener">Meysam's LinkedIn Post</a>
- Claude E. Shannon
  - <a href="https://dspace.mit.edu/handle/1721.1/11173" target="_blank" rel="noreferrer noopener">A symbolic analysis of relay and switching circuits</a> (Master's Thesis)
  - <a href="https://ieeexplore.ieee.org/document/6769090" target="_blank" rel="noreferrer noopener">Communication theory of secrecy systems</a>
  - <a href="https://ieeexplore.ieee.org/document/6773024" target="_blank" rel="noreferrer noopener">A mathematical theory of communication</a>
  - <a href="https://ieeexplore.ieee.org/document/6773263" target="_blank" rel="noreferrer noopener">Prediction and entropy of printed English</a>
- <a href="https://bounded-regret.ghost.io/future-ml-systems-will-be-qualitatively-different/" target="_blank" rel="noreferrer noopener">Future ML Systems Will Be Qualitatively Different</a>
- <a href="https://www.science.org/doi/10.1126/science.177.4047.393?ref=bounded-regret.ghost.io" target="_blank" rel="noreferrer noopener">More Is Different</a>
- <a href="https://arxiv.org/abs/2401.05566" target="_blank" rel="noreferrer noopener">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</a>
- <a href="https://arxiv.org/abs/2304.15004" target="_blank" rel="noreferrer noopener">Are Emergent Abilities of Large Language Models a Mirage?</a>
- <a href="https://arxiv.org/abs/2309.01809" target="_blank" rel="noreferrer noopener">Are Emergent Abilities of Large Language Models just In-Context Learning?</a>
- <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer noopener">Attention is all you need</a>
- <a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noreferrer noopener">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a>
- <a href="https://arxiv.org/abs/2402.01306" target="_blank" rel="noreferrer noopener">KTO: Model Alignment as Prospect Theoretic Optimization</a>
- <a href="https://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/TemperAnneal/KirkpatrickAnnealScience1983.pdf" target="_blank" rel="noreferrer noopener">Optimization by Simulated Annealing</a>
- <a href="https://openai.com/blog/memory-and-new-controls-for-chatgpt" target="_blank" rel="noreferrer noopener">Memory and new controls for ChatGPT</a>
- <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4515540/" target="_blank" rel="noreferrer noopener">Hallucinations and related concepts—their conceptual background</a>
<!-- end of the list -->
