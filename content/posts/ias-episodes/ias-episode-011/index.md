---
url: /intoaisafety/e011/
title: Evals Hackathon November 2023 (2)
summary: The hackathon team's second meeting, during which we solidify our goals and discuss initial experimentation.
date: 2024-02-05
lastmod: 2024-06-17

image:
  caption: 'Into AI Safety Cover Art'
  preview_only: true
  filename: ias_cover_art.jpeg

authors:
  - intoaisafety

tags:
  - Hackathon
  - Research
  - Evals November 2023

categories: 
  - Podcast
---

<div style="text-align: justify">
Join our hackathon group for the second episode in the Evals November 2023 Hackathon subseries. In this episode, we solidify our goals for the hackathon after some preliminary experimentation and ideation.

{{< transistor src="https://share.transistor.fm/e/b1493509" >}}

Check out Stellaric's <a href="https://stellaric.pw/" target="_blank" rel="noreferrer noopener">website</a>, or follow them on <a href="https://twitter.com/stellaricpw" target="_blank" rel="noreferrer noopener">Twitter</a>.
</div>

### Chapters

<div style="text-align: left; font-family:monospace;">
01:53 ❙ Meeting starts<br>
05:05 ❙ Pitch: extension of locked models<br>
23:23 ❙ Pitch: retroactive holdout datasets<br>
34:04 ❙ Preliminary results<br>
37:44 ❙ Next steps<br>
42:55 ❙ Recap
</div>

### Links

Links to all articles/papers which are mentioned throughout the episode can be found below, in order of their appearance.
- <a href="https://github.com/LRudL/evalugator" target="_blank" rel="noreferrer noopener">Evalugator</a> library
- <a href="https://www.alignmentforum.org/posts/rZs6ddqNnW8LXuJqA/password-locked-models-a-stress-case-for-capabilities" target="_blank" rel="noreferrer noopener">Password Locked Models</a> blogpost
- <a href="https://arxiv.org/abs/2109.07958" target="_blank" rel="noreferrer noopener">TruthfulQA: Measuring How Models Mimic Human Falsehoods</a>
- <a href="https://aclanthology.org/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>
- <a href="https://arxiv.org/abs/1905.10044" target="_blank" rel="noreferrer noopener">BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions</a>
- <a href="https://arxiv.org/abs/2310.16789" target="_blank" rel="noreferrer noopener">Detecting Pretraining Data from Large Language Models</a>

<!-- end of the list -->