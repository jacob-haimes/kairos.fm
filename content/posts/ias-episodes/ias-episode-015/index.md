---
url: /intoaisafety/e015/
title: StakeOut.AI w/ Dr. Peter Park (1)
summary: Dr. Peter Park, an AI Existential Safety Postdoctoral Fellow working with Dr. Max Tegmark at MIT, joins me to discuss his non-profit, StakeOut.AI.
date: 2024-03-04
lastmod: 2024-06-18

image:
  caption: 'Into AI Safety Cover Art'
  preview_only: true
  filename: ias_cover_art.jpeg

authors:
  - intoaisafety

tags:
  - Interview
  - StakeOut.AI Feb 2024
  - AISC

categories: 
  - Podcast
---

<div style="text-align: justify">
Dr. Peter Park is an AI Existential Safety Postdoctoral Fellow working with Dr. Max Tegmark at MIT. In conjunction with Harry Luk and one other cofounder, he founded <a href="https://www.stakeout.ai" target="_blank" rel="noreferrer noopener">StakeOut.AI</a>, a non-profit focused on making AI go well _for humans_.

{{< transistor src="https://share.transistor.fm/e/81a6fb5c" >}}
</div>

### Chapters

<div style="text-align: left; font-family:monospace;">
00:54 ❙ Intro<br>
03:15 ❙ Dr. Park, x-risk, and AGI<br>
08:55 ❙ StakeOut.AI<br>
12:05 ❙ Governance scorecard<br>
19:34 ❙ Hollywood webinar<br>
22:02 ❙ Regulations.gov comments<br>
23:48 ❙ Open letters <br>
26:15 ❙ EU AI Act<br>
35:07 ❙ Effective accelerationism<br>
40:50 ❙ Divide and conquer dynamics<br>
45:40 ❙ AI "art"<br>
53:09 ❙ Outro
</div>

Links to all articles/papers which are mentioned throughout the episode can be found below, in order of their appearance.

- <a href="https://www.stakeout.ai" target="_blank" rel="noreferrer noopener">StakeOut.AI</a>
- <a href="https://futureoflife.org/wp-content/uploads/2023/11/FLI_Governance_Scorecard_and_Framework.pdf" target="_blank" rel="noreferrer noopener">AI Governance Scorecard</a> (go to Pg. 3)
- <a href="https://pauseai.info" target="_blank" rel="noreferrer noopener">Pause AI</a>
- <a href="https://www.regulations.gov" target="_blank" rel="noreferrer noopener">Regulations.gov</a>
  - <a href="https://www.regulations.gov/comment/COLC-2023-0006-10077" target="_blank" rel="noreferrer noopener">USCO StakeOut.AI Comment</a>
  - <a href="https://www.regulations.gov/comment/OMB-2023-0020-0170" target="_blank" rel="noreferrer noopener">OMB StakeOut.AI Comment</a>
- <a href="https://aitreaty.org" target="_blank" rel="noreferrer noopener">AI Treaty open letter</a>
- <a href="https://taisc.org" target="_blank" rel="noreferrer noopener">TAISC</a>
- <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" target="_blank" rel="noreferrer noopener">Alpaca: A Strong, Replicable Instruction-Following Model</a>
- References on EU AI Act and Cedric O
  - <a href="https://twitter.com/cedric_o/status/1728724005459235052" target="_blank" rel="noreferrer noopener">Tweet from Cedric O</a>
  - <a href="https://www.euractiv.com/section/artificial-intelligence/news/eu-policymakers-enter-the-last-mile-for-artificial-intelligence-rulebook/" target="_blank" rel="noreferrer noopener">EU policymakers enter the last mile for Artificial Intelligence rulebook</a>
  - <a href="https://www.euractiv.com/section/artificial-intelligence/news/ai-act-eu-parliaments-legal-office-gives-damning-opinion-on-high-risk-classification-filters/" target="_blank" rel="noreferrer noopener">AI Act: EU Parliament’s legal office gives damning opinion on high-risk classification ‘filters’</a>
  - <a href="https://www.euractiv.com/section/artificial-intelligence/news/eus-ai-act-negotiations-hit-the-brakes-over-foundation-models/" target="_blank" rel="noreferrer noopener">EU’s AI Act negotiations hit the brakes over foundation models</a>
  - <a href="https://www.foundation-models.eu" target="_blank" rel="noreferrer noopener">The EU AI Act needs Foundation Model Regulation</a>
  - <a href="https://verfassungsblog.de/bigtechs-efforts-to-derail-the-ai-act/" target="_blank" rel="noreferrer noopener">BigTech’s Efforts to Derail the AI Act</a>
- <a href="https://demos.co.uk/research/open-sourcing-the-ai-revolution-framing-the-debate-on-open-source-artificial-intelligence-and-regulation/" target="_blank" rel="noreferrer noopener">Open Sourcing the AI Revolution: Framing the debate on open source, artificial intelligence and regulation</a>
- <a href="https://arxiv.org/abs/2310.06009" target="_blank" rel="noreferrer noopener">Divide-and-Conquer Dynamics in AI-Driven Disempowerment</a>

<!-- end of the list -->
