---
url: /intoaisafety/e019/
title: Scaling Democracy w/ Dr. Igor Krawczuk
summary: "Dr. Igor Krawczuk joins me for one massive episode that covers all the classics: eugenics, capitalism, philosophical toads... Need I say more?"
date: 2024-05-21
lastmod: 2024-06-18

featured: true

image:
  caption: 'Into AI Safety Cover Art'
  preview_only: true
  filename: ias_cover_art.jpeg

authors:
  - intoaisafety

tags:
  - Interview
  - Narratives & Hype
  - Effective Altruism

categories:
  - Podcast
---

<div style="text-align: justify">
The *almost* Dr. Igor Krawczuk joins me for what is the equivalent of 4 of my previous episodes. We get into all the classics: eugenics, capitalism, philosophical toads... Need I say more?

{{< transistor src="https://share.transistor.fm/e/b8225038" >}}

If you're interested in connecting with Igor, head on over to his <a href="https://krawczuk.eu" target="_blank" rel="noreferrer noopener">website</a>, or check out his <a href="https://infoscience.epfl.ch/entities/publication/8a267366-77e7-473a-82e1-a2e3fa4d9563" target="_blank" rel="noreferrer noopener">thesis</a>!
</div>

Because these shownotes have a whopping 115 additional links below, I'll highlight some that I think are particularly worthwhile:
- The best article you'll ever read on <a href="https://jacob-haimes.github.io/independent/Open-Source-AI-is-a-lie/" target="_blank" rel="noreferrer noopener">Open Source AI</a>
- The best article you'll ever read on <a href="https://www.odysseaninstitute.org/post/let-s-talk-about-emergence" target="_blank" rel="noreferrer noopener">emergence in ML</a>
- Kate Crawford's _<a href="https://yalebooks.yale.edu/book/9780300264630/atlas-of-ai/" target="_blank" rel="noreferrer noopener">Atlas of AI</a>_ (<a href="https://en.wikipedia.org/wiki/Atlas_of_AI" target="_blank" rel="noreferrer noopener">Wikipedia</a>)
- <a href="https://arxiv.org/abs/1911.01547" target="_blank" rel="noreferrer noopener">On the Measure of Intelligence</a>
- Thomas Piketty's _<a href="https://www.hup.harvard.edu/books/9780674430006" target="_blank" rel="noreferrer noopener">Capital in the Twenty-First Century</a>_ (<a href="https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Century" target="_blank" rel="noreferrer noopener">Wikipedia</a>)
- Yurii Nesterov's _<a href="https://books.google.com/books?hl=en&lr=&id=2-ElBQAAQBAJ&oi=fnd&pg=PA1&dq=info:JTiRBrZ_LZMJ:scholar.google.com&ots=wnpRdsxjjv&sig=1Oa-5P-zZZ_MX_2MFKv5cq2fx48#v=onepage&q&f=false" target="_blank" rel="noreferrer noopener">Introductory Lectures on Convex Optimization</a>_


### Chapters

<div style="text-align: left; font-family:monospace;">

00:02:32 ‚ùô Introducing Igor<br>
00:10:11 ‚ùô Aside on EY, LW, EA, etc., a.k.a. lettersoup<br>
00:18:30 ‚ùô Igor on AI alignment<br>
00:33:06 ‚ùô "Open Source" in AI<br>
00:41:20 ‚ùô The story of infinite riches and suffering<br>
00:59:11 ‚ùô On AI threat models<br>
01:09:25 ‚ùô Representation in AI<br>
01:15:00 ‚ùô Hazard fishing<br>
01:18:52 ‚ùô Intelligence and eugenics<br>
01:34:38 ‚ùô Emergence<br>
01:48:19 ‚ùô Considering externalities<br>
01:53:33 ‚ùô The shape of an argument<br>
02:01:39 ‚ùô More eugenics<br>
02:06:09 ‚ùô I'm convinced, what now?<br>
02:18:03 ‚ùô AIxBio (round ??)<br>
02:29:09 ‚ùô On open release of models<br>
02:40:28 ‚ùô Data and copyright<br>
02:44:09 ‚ùô Scientific accessibility and bullshit<br>
02:53:04 ‚ùô Igor's point of view<br>
02:57:20 ‚ùô Outro
</div>

### Links

Links to all articles/papers which are mentioned throughout the episode can be found below, in order of their appearance. All references, including those only mentioned in the extended version of this episode, are included.
- <a href="https://www.epfl.ch/labs/lions/" target="_blank" rel="noreferrer noopener">LIONS Lab</a> at EPFL
- The <a href="https://pbs.twimg.com/media/D53Q_MYW4AA-wRK.jpg" target="_blank" rel="noreferrer noopener">meme</a> that Igor references
- <a href="https://arxiv.org/abs/2401.01869" target="_blank" rel="noreferrer noopener">On the Hardness of Learning Under Symmetries</a>
- <a href="https://uvagedl.github.io" target="_blank" rel="noreferrer noopener">Course</a> on the concept of equivariant deep learning
- Aside on EY/EA/etc.
  - Sources on Eliezer Yudkowski
    - <a href="https://encyclopedia.pub/entry/33978" target="_blank" rel="noreferrer noopener">Scholarly Community Encyclopedia</a>
    - <a href="https://time.com/collection/time100-ai/6309037/eliezer-yudkowsky/" target="_blank" rel="noreferrer noopener">TIME100 AI</a>
    - Yudkowski's personal <a href="https://www.yudkowsky.net" target="_blank" rel="noreferrer noopener">website</a>
    - <a href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky" target="_blank" rel="noreferrer noopener">EY Wikipedia</a>
    - <a href="https://whatshouldiread.fandom.com/wiki/Eliezer_Yudkowsky#cite_note-1" target="_blank" rel="noreferrer noopener">A Very Literary Wiki</a>
    -TIME article: <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/" target="_blank" rel="noreferrer noopener">Pausing AI Developments Isn‚Äôt Enough. We Need to Shut it All Down</a> documenting EY's ruminations of bombing datacenters; this comes up later in the episode but is included here because it about EY.
  - <a href="https://www.lesswrong.com" target="_blank" rel="noreferrer noopener">LessWrong</a>
    - <a href="https://en.wikipedia.org/wiki/LessWrong" target="_blank" rel="noreferrer noopener">LW Wikipedia</a>
  - <a href="https://intelligence.org" target="_blank" rel="noreferrer noopener">MIRI</a>
  - Coverage on Nick Bostrom (being a racist)
    - The Guardian article: <a href="https://www.theguardian.com/technology/2024/apr/28/nick-bostrom-controversial-future-of-humanity-institute-closure-longtermism-affective-altruism" target="_blank" rel="noreferrer noopener">‚ÄòEugenics on steroids‚Äô: the toxic and contested legacy of Oxford‚Äôs Future of Humanity Institute</a>
    - The Guardian article: <a href="https://www.theguardian.com/technology/2024/apr/19/oxford-future-of-humanity-institute-closes" target="_blank" rel="noreferrer noopener">Oxford shuts down institute run by Elon Musk-backed philosopher</a>
  - Investigative <a href="https://markfuentes1.substack.com/p/emile-p-torress-history-of-dishonesty" target="_blank" rel="noreferrer noopener">piece</a> on √âmile Torres
  - <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank" rel="noreferrer noopener">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú</a>
  - NY Times article: <a href="https://www.nytimes.com/2019/11/11/technology/artificial-intelligence-bias.html" target="_blank" rel="noreferrer noopener">We Teach A.I. Systems Everything, Including Our Biases</a>
  - NY Times article: <a href="https://www.nytimes.com/2020/12/03/technology/google-researcher-timnit-gebru.html" target="_blank" rel="noreferrer noopener">Google Researcher Says She Was Fired Over Paper Highlighting Bias in A.I.</a>
  - Timnit Gebru's <a href="https://en.wikipedia.org/wiki/Timnit_Gebru" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - <a href="https://firstmonday.org/ojs/index.php/fm/article/view/13636" target="_blank" rel="noreferrer noopener">The TESCREAL Bundle: Eugenics and the Promise of Utopia through Artificial General Intelligence</a>
  - Sources on the environmental impact of LLMs
    - <a href="https://analyticsindiamag.com/the-environmental-impact-of-llms/" target="_blank" rel="noreferrer noopener">The Environmental Impact of LLMs</a>
    - <a href="https://tinyml.substack.com/p/the-cost-of-inference-running-the" target="_blank" rel="noreferrer noopener">The Cost of Inference: Running the Models</a>
    - <a href="https://arxiv.org/abs/1906.02243" target="_blank" rel="noreferrer noopener">Energy and Policy Considerations for Deep Learning in NLP</a>
    - <a href="https://weareyard.com/insights/the-carbon-impact-of-ai-vs-search-engines" target="_blank" rel="noreferrer noopener">The Carbon Impact of AI vs Search Engines</a>
- <a href="https://www.science.org/doi/full/10.1126/science.abi7176?casa_token=2txe0r_jjhQAAAAA%3ALJa__HZL9COyj9EUpdILZdtnMKLyggfFe7Zpvv0tNze62rLO0CoQHCCJiXfruxUeBLj3YBZ33F8OOv0u" target="_blank" rel="noreferrer noopener">Filling Gaps in Trustworthy Development of AI
</a> (Igor is an author on this one)
- <a href="https://www.hindawi.com/journals/complexity/2022/8210732/" target="_blank" rel="noreferrer noopener">A Computational Turn in Policy Process Studies: Coevolving Network Dynamics of Policy Change</a>
- <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/7e05d6f828574fbc975a896b25bb011e-Paper.pdf" target="_blank" rel="noreferrer noopener">The Smoothed Possibility of Social Choice</a>, an intro in social choice theory and how it overlaps with ML
- Relating to Dan Hendrycks
  - <a href="https://arxiv.org/abs/2303.16200" target="_blank" rel="noreferrer noopener">Natural Selection Favors AIs over Humans</a>
    - "One easy-to-digest source to highlight what he gets wrong [is] <a href="https://pressbooks.calstate.edu/explorationsbioanth2/chapter/17/" target="_blank" rel="noreferrer noopener">Social and Biopolitical Dimensions of Evolutionary Thinking</a>" -Igor
  - <a href="https://www.aisafetybook.com" target="_blank" rel="noreferrer noopener">Introduction to AI Safety, Ethics, and Society</a>, recently published textbook
  - "<a href="https://arxiv.org/pdf/2306.12001#page=10.19" target="_blank" rel="noreferrer noopener">Source</a> to the section [of this paper] that makes Dan one of my favs from that crowd." -Igor
  - <a href="https://twitter.com/DanHendrycks/status/1710312043503321141" target="_blank" rel="noreferrer noopener">Twitter post</a> referenced in the episode
- <a href="https://proceedings.mlr.press/v162/langosco22a.html" target="_blank" rel="noreferrer noopener">Goal Misgeneralization in Deep Reinforcement Learning</a>
- The YouTube Radicalization Pipeline
  - MIT Technology Review article: <a href="https://www.technologyreview.com/2020/01/29/276000/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/" target="_blank" rel="noreferrer noopener">YouTube‚Äôs Algorithm Seems to be Funneling People to Alt-Right Videos</a>
  - <a href="https://arxiv.org/abs/1908.08313" target="_blank" rel="noreferrer noopener">Auditing Radicalization Pathways on YouTube</a>
- <a href="https://www.cs.toronto.edu/~cebly/Papers/SlateQ_IJCAI_2019.pdf" target="_blank" rel="noreferrer noopener">SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets</a>
- The best article you'll ever read on <a href="https://jacob-haimes.github.io/independent/Open-Source-AI-is-a-lie/" target="_blank" rel="noreferrer noopener">Open Source AI</a>
- <a href="https://www.lighthousereports.com/suspicion-machines-methodology/" target="_blank" rel="noreferrer noopener">Suspicious Machines Methodology</a>, referred to as the "Rotterdam Lighthouse Report" in the episode
- <a href="https://arxiv.org/abs/2312.09390" target="_blank" rel="noreferrer noopener">Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision</a>
- <a href="https://arxiv.org/abs/2312.06942" target="_blank" rel="noreferrer noopener">AI Control: Improving Safety Despite Intentional Subversion</a>
- Additional reading on mechanism design
  - General: <a href="https://books.google.ch/books?hl=en&lr=&id=1uGrBwAAQBAJ&oi=fnd&pg=PP1&dq=mechanism+design&ots=nAFspRa_dJ&sig=u9-a2eJslA9SENGtnGAyq--RLoc&redir_esc=y#v=onepage&q=mechanism%20design&f=false" target="_blank" rel="noreferrer noopener">An Introduction to the Theory of Mechanism Design</a>
  - Relating to ML: <a href="https://ieeexplore.ieee.org/abstract/document/6686198?casa_token=qrJHumQEZLMAAAAA:oPXWIT6MICD8s8_jxMOFzARgNDsK9R4uLtEJNNpTwszVS1gxomrpAts-6c78ExnNSX5ASdcy6-Gd" target="_blank" rel="noreferrer noopener">Understanding Incentives: Mechanism Design Becomes Algorithm Design</a>
  - Example in ML: <a href="https://arxiv.org/abs/2306.05221" target="_blank" rel="noreferrer noopener">Steering No-Regret Learners to a Desired Equilibrium</a>
- The more important <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/jordan.html" target="_blank" rel="noreferrer noopener">Michael Jordan</a>
- Pascal's Mugging and Risk
  - Pascal's Mugging <a href="https://en.wikipedia.org/wiki/Pascal%27s_mugging" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - <a href="https://www.youtube.com/watch?v=5pYeoZaoWrA&t=408s" target="_blank" rel="noreferrer noopener">This is Financial Advice</a>, a long video on the memestock phenomenon
  - Slides on <a href="https://ethz.ch/content/dam/ethz/special-interest/math/risklab-dam/documents/risk-day/risk-day-2019/Ebert_2019_09_13.pdf" target="_blank" rel="noreferrer noopener">Skewness Preferences in Choice Under Risk</a>
- Intelligence, eugenics, and toads
  - <a href="https://arxiv.org/abs/1911.01547" target="_blank" rel="noreferrer noopener">On the Measure of Intelligence</a>
  - <a href="https://www.sciencedirect.com/science/article/pii/S0896627312005843" target="_blank" rel="noreferrer noopener">Fractionating Human Intelligence</a>
  - <a href="https://monthlyreview.org/2022/09/01/intelligence-under-racial-capitalism-from-eugenics-to-standardized-testing-and-online-learning/" target="_blank" rel="noreferrer noopener">Intelligence Under Racial Capitalism: From Eugenics to Standardized Testing and Online Learning</a>
  - The Physics of Superheroes <a href="https://en.wikipedia.org/wiki/The_Physics_of_Superheroes" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - <a href="https://idlewords.com/talks/superintelligence.htm" target="_blank" rel="noreferrer noopener">Superintelligence: The Idea That Eats Smart People</a>
    - <a href="https://pinboard.in" target="_blank" rel="noreferrer noopener">Pinboard</a>
- <a href="https://www.trade.gov/usmca-overview" target="_blank" rel="noreferrer noopener">NAFTA</a>
- Lack of representation in AI
  - The Guardian article: <a href="https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people" target="_blank" rel="noreferrer noopener">Google's solution to accidental algorithmic racism: ban gorillas</a>
  - TIME article: <a href="https://time.com/6836153/ethical-ai-google-gemini-debacle/" target="_blank" rel="noreferrer noopener">Ethical AI Isn‚Äôt to Blame for Google‚Äôs Gemini Debacle</a>
  - TIME article: <a href="https://time.com/6755968/google-gemini-images-race/" target="_blank" rel="noreferrer noopener">Google Pauses AI-Made Images of People After Race Inaccuracies</a>
  - The Guardian article: <a href="https://www.theguardian.com/technology/2015/jul/01/google-sorry-racist-auto-tag-photo-app" target="_blank" rel="noreferrer noopener">Google says sorry for racist auto-tag in photo app</a>
- Emergence
  - The best article you'll ever read on <a href="https://www.odysseaninstitute.org/post/let-s-talk-about-emergence" target="_blank" rel="noreferrer noopener">emergence in ML</a>
  - <a href="https://arxiv.org/abs/2309.01809" target="_blank" rel="noreferrer noopener">Are Emergent Abilities in Large Language Models just In-Context Learning?</a>
  - <a href="https://arxiv.org/abs/2206.07682" target="_blank" rel="noreferrer noopener">Emergent Abilities of Large Language Models</a>
  - <a href="https://arxiv.org/abs/2304.15004" target="_blank" rel="noreferrer noopener">Are Emergent Abilities of Large Language Models a Mirage?</a>
  - <a href="https://arxiv.org/abs/2401.05566" target="_blank" rel="noreferrer noopener">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</a>
- CICERO paper: <a href="https://www.science.org/doi/10.1126/science.ade9097" target="_blank" rel="noreferrer noopener">Human-level play in the game of Diplomacy by combining language models with strategic reasoning</a>
- Kate Crawford's _<a href="https://yalebooks.yale.edu/book/9780300264630/atlas-of-ai/" target="_blank" rel="noreferrer noopener">Atlas of AI</a>_
- Malcolm Harris' _<a href="https://www.goodreads.com/book/show/61108472-palo-alto" target="_blank" rel="noreferrer noopener">Palo Alto: A History of California, Capitalism, and the World</a>_
- Thomas Piketty's _<a href="https://www.hup.harvard.edu/books/9780674980822" target="_blank" rel="noreferrer noopener">Capital and Ideology</a>_
- Video debunking <a href="https://www.youtube.com/watch?v=UBc7qBS1Ujo" target="_blank" rel="noreferrer noopener">The Bell Curve</a>
- Occam's razor <a href="https://en.wikipedia.org/wiki/Occam%27s_razor" target="_blank" rel="noreferrer noopener">Wikipedia</a>
- <a href="https://static1.squarespace.com/static/6461e2a5c6399341bcfc84a5/t/654bc268049d687cecac24d8/1699463818729/auditing_framework_web.pdf" target="_blank" rel="noreferrer noopener">A Causal Framework for AI Regulation and Auditing</a>
- <a href="https://arxiv.org/abs/1811.04502" target="_blank" rel="noreferrer noopener">A Simple Combinatorial Model of World Economic History</a>
- Cambridge Analytica <a href="https://en.wikipedia.org/wiki/Cambridge_Analytica" target="_blank" rel="noreferrer noopener">Wikipedia</a>
- Previous <a href="https://www.youtube.com/watch?v=lxaTinmKxs0" target="_blank" rel="noreferrer noopener">interview</a> w/ Igor and Carla Cremer
- Roko's basilisk
  - <a href="https://rationalwiki.org/wiki/Roko%27s_basilisk" target="_blank" rel="noreferrer noopener">RationalWiki</a>
    - Specific <a href="https://rationalwiki.org/wiki/Roko's_basilisk#cite_note-takenseriously-6" target="_blank" rel="noreferrer noopener">source</a> highlighted by Igor
    - <a href="https://www.lesswrong.com/posts/ZZTTranBLHwSjrt7g/in-wikipedia-reading-about-roko-s-basilisk-causing-nervous" target="_blank" rel="noreferrer noopener">Counterpoint</a>
  - <a href="https://www.youtube.com/watch?v=YGNNTxWkjl8" target="_blank" rel="noreferrer noopener">Point/Counterpoint</a>
- Eugenics and bigots
  - Scott Siskind
    - Old Reddit discussion on <a href="https://old.reddit.com/r/SneerClub/comments/lm36nk/old_scott_siskind_emails_which_link_him_to_the/" target="_blank" rel="noreferrer noopener">Scott Siskind Emails</a>
    - <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/" target="_blank" rel="noreferrer noopener">Meditations on Moloch</a> from Slate Star Codex, a.k.a. Scott Sickind's old blog
    - Discussion on Scott Siskind's eugenecist rhetoric: <a href="https://awful.systems/post/904078" target="_blank" rel="noreferrer noopener">awful.systems</a>
    - <a href="https://www.eruditorumpress.com/blog/the-beigeness-or-how-to-kill-people-with-bad-writing-the-scott-alexander-method#:~:text=Siskind%E2%80%99s%20defenders%20to%20pull%20shit%20like%20saying%20%E2%80%9Cbut%20he%20voted%20for%20Warren%E2%80%9D%20as%20a%20defense%20when%20someone%20points%20out%20that%20he%20openly%20supports%20eugenics" target="_blank" rel="noreferrer noopener">The Beigeness, or How to Kill People with Bad Writing: The Scott Alexander Method</a>
    - NY Times article: <a href="https://www.nytimes.com/2021/02/13/technology/slate-star-codex-rationalists.html" target="_blank" rel="noreferrer noopener">Silicon Valley‚Äôs Safe Space</a>
  - <a href="https://nickbostrom.com/papers/vulnerable.pdf" target="_blank" rel="noreferrer noopener">The Vulnerable World Hypothesis</a> or "Nick Bostrom's Black Ball paper"
  - Definition of Ur-Fascism on <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco" target="_blank" rel="noreferrer noopener">Wikipedia</a>
- Video: <a href="https://www.youtube.com/watch?v=EiZhdpLXZ8Q" target="_blank" rel="noreferrer noopener">The Future is a Dead Mall - Decentraland and the Metaverse</a>
- Wired article: <a href="https://www.wired.com/story/the-libertarian-logic-of-peter-thiel/" target="_blank" rel="noreferrer noopener">The Libertarian Logic of Peter Thiel</a>
- Hegel
  - <a href="https://plato.stanford.edu/entries/hegel-dialectics/" target="_blank" rel="noreferrer noopener">Hegel's Dialectics</a>
  - Video: <a href="https://www.youtube.com/watch?v=OgNt1C72B_4&pp=ygUhaGVnZWxpYW4gZGlhbGVjdGljIHBoaWxzb3BoeSB0dWJl" target="_blank" rel="noreferrer noopener">Intro to Hegel (& Progressive Politics) | Philosophy Tube</a>
- <a href="https://math.stackexchange.com/a/2687380" target="_blank" rel="noreferrer noopener">If you assume 1 = 2, you can prove that I'm the Pope</a>
- The <a href="https://raft.github.io/" target="_blank" rel="noreferrer noopener">Raft</a> algorithm
- Video: <a href="https://www.youtube.com/watch?v=4xGawJIseNY&list=PLJA_jUddXvY7v0VkYRbANnTnzkA_HMFtQ" target="_blank" rel="noreferrer noopener">The Alt-Right Playbook</a>
- Igor's resources short-list
  - <a href="https://www.tandfonline.com/doi/full/10.1080/01969722.2016.1209375?casa_token=nQub0q8WfkQAAAAA%3A5CEIdF3-S9GxPyIAqygeISfFDuNyrJ6FQgHMrZY68R2q_TX4aA1Er-yZBCoGWXb8mQbZu5rI9XlTglo" target="_blank" rel="noreferrer noopener">A Test of the Viable System Model: Theoretical Claim vs. Empirical Evidence</a>
  - Jane Jacobs' _The Death and Life of Great American Cities_ <a href="https://en.wikipedia.org/wiki/The_Death_and_Life_of_Great_American_Cities" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - David Graeber's _Debt: The First 5000 Years_ <a href="https://en.wikipedia.org/wiki/Debt:_The_First_5000_Years" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - Thomas Piketty's Capital in the Twenty-First Century <a href="https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Century" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - Yurii Nesterov's _<a href="https://books.google.com/books?hl=en&lr=&id=2-ElBQAAQBAJ&oi=fnd&pg=PA1&dq=info:JTiRBrZ_LZMJ:scholar.google.com&ots=wnpRdsxjjv&sig=1Oa-5P-zZZ_MX_2MFKv5cq2fx48#v=onepage&q&f=false" target="_blank" rel="noreferrer noopener">Introductory Lectures on Convex Optimization</a>_
- Secure Socket Layer (SSL) <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0" target="_blank" rel="noreferrer noopener">Wikipedia</a>
- AIxBio (most of these are repeat references from previous episodes)
  - <a href="https://www.rand.org/pubs/research_reports/RRA2977-2.html?utm_source=substack&utm_medium=email" target="_blank" rel="noreferrer noopener">The Operational Risks of AI in Large-Scale Biological Attacks</a>
  - <a href="https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation/?utm_source=substack&utm_medium=email" target="_blank" rel="noreferrer noopener">Building an early warning system for LLM-aided biological threat creation</a>
  - <a href="https://arxiv.org/abs/2306.03809" target="_blank" rel="noreferrer noopener">Can large language models democratize access to dual-use biotechnology?</a>
  - <a href="https://arxiv.org/abs/2310.18233" target="_blank" rel="noreferrer noopener">Will releasing the weights of future large language models grant widespread access to pandemic agents?</a>
  - <a href="https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models" target="_blank" rel="noreferrer noopener">Open-Sourcing Highly Capable Foundation Models</a>
  - <a href="https://1a3orn.com/sub/essays-propaganda-or-science.html" target="_blank" rel="noreferrer noopener">Propaganda or Science: Open Source AI and Bioterrorism Risk</a>
  - <a href="https://ineffectivealtruismblog.com/2024/03/09/exaggerating-the-risks-part-14-biorisk-from-llms/" target="_blank" rel="noreferrer noopener">Exaggerating the risks (Part 15: Biorisk from LLMs)</a>
  - <a href="https://crfm.stanford.edu/open-fms/" target="_blank" rel="noreferrer noopener">On the Societal Impact of Open Foundation Models</a>
  - Tokyo subway sarin attack <a href="https://en.wikipedia.org/wiki/Tokyo_subway_sarin_attack#:~:text=They%20had%20also%20produced%20several%20other%20nerve%20agents%2C%20including%20VX%2C%20and%20attempted%20to%20produce%20botulinum%20toxin%20and%20had%20perpetrated%20several%20failed%20acts%20of%20bioterrorism" target="_blank" rel="noreferrer noopener">Wikipedia</a>
- <a href="https://spectrum.ieee.org/midjourney-copyright" target="_blank" rel="noreferrer noopener">Generative AI Has a Visual Plagiarism Problem</a>, a.k.a. "The Gary Marcus report"
  - A follow-up from Gary Marcus: <a href="https://garymarcus.substack.com/p/things-are-about-to-get-a-lot-worse" target="_blank" rel="noreferrer noopener">Things are about to get a lot worse for Generative AI</a>
- Monte-Carlo Tree Search (MCTS) <a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" target="_blank" rel="noreferrer noopener">Wikipedia</a>
  - <a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#cite_note-15" target="_blank" rel="noreferrer noopener">Source</a> highlighted by Igor
- <a href="https://www.semanticscholar.org/paper/The-Rhetoric-of-Economics-McCloskey/fa0aa6f21b5cc1ba331999f39188c02a9c442db2" target="_blank" rel="noreferrer noopener">The Rhetoric of Economics</a>
- <a href="https://complexityzoo.net/Complexity_Zoo" target="_blank" rel="noreferrer noopener">Complexity Zoo</a>
- <a href="https://ncatlab.org/nlab/show/HomePage" target="_blank" rel="noreferrer noopener">nLab</a>

<!-- end of the list -->
