---
# url: /
title: "Introduction to AI Safety and Ethics for Non-Technical Professionals"
summary: Video recording of the LearnTech webinar on AI safety and ethics.
date: 2024-10-03
lastmod: 2024-10-30

_build:
  render: never
  list: never
cascade:
  _build:
    render: never
    list: never

image:
  caption: 'muckrAIkers Temporary Cover Art'
  preview_only: true
  filename: muckraikers_cover-art.jpg

authors:
  - sucizem

tags:
  - '"AI"'
  - AI Governance
  - Machine Learning

categories: 
  - Video
---

{{< youtube 4pZ1KYf3ZvY >}}
<br>

## Poll Results
<div style="text-align: justify">

During the webinar, we conducted two polls: one at the beginning to understand initial views on AI safety, and another at the end to see if these perspectives had shifted after engaging with the material presented. At the end of this email, you can find the visualization of the two polls.

The results showed the following changes:

- **More Concerned:** 22.2%
- **Less Concerned:** 11.1%
- **Unchanged:** 66.7%
</div>

## List of Resources

<div style="text-align: justify">

As promised, we have compiled a list of resources to help you deepen your understanding of the topics discussed. These resources cover a wide range of areas related to AI safety, including technical background, governance, historical case studies, and practical approaches to managing risks. Many of these resources have been curated from the [BlueDot Impact AI Alignment](https://course.aisafetyfundamentals.com/alignment) and [Governance](https://course.aisafetyfundamentals.com/governance) curriculums, as well as the [Center for AI Safety textbook](https://www.aisafetybook.com/). I encourage you to explore these courses for a more comprehensive dive into the materials. Below is a categorized list of references and readings that will assist you in exploring AI alignment and governance further.

### Overview
- **"5% chance of AI causing humans to go extinct"**<br>A survey of 2,700 AI researchers reveals that a significant number believe in the non-trivial risk of human extinction due to the development of superhuman AI.
- **International AI Safety Report**<br>Synthesizes scientific evidence on the safety of current and future general-purpose AI systems.

</div>


### Technical Background

*From the Bluedot Impact AI Alignment Curriculum:*
- **But what is a neural network?** by 3Blue1Brown (2017)
- **Gradient descent, how neural networks learn** by 3Blue1Brown (2017)
- **Intro to Large Language Models** by Andrej Karpathy (2023)
- **Visualizing the Deep Learning Revolution** by Richard Ngo (2023)
- **Compute Trends Across Three Eras of Machine Learning** by Epoch AI (2022)
- **The True Story of How GPT-2 Became Maximally Lewd** by Rational Animations
- **Illustrating Reinforcement Learning from Human Feedback (RLHF)** by Nathan Lambert, Louis Castricato, and Leandro von Werra et al.
- **Constitutional AI: Harmlessness from AI Feedback** by Yuntao Bai and Jared Kaplan
- **Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback** by Stephen Casper and Xander Davies
- **Adversarial Machine Learning** by Letiția Pârcălăbescu (2020)
- **Universal and Transferable Adversarial Attacks on Aligned Language Models** by Andy Zou, Zifan Wang, Nicholas Carlini et al. (2023)
- **Deep Forgetting & Unlearning for Safely-Scoped LLMs** by Stephen Casper (2023)
- **Measuring and Reducing Malicious Use With Unlearning** by Nathaniel Li, Alexander Pan et al. (2024)
- **AI Control: Improving Safety Despite Intentional Subversion** by Buck Shlegeris, Fabien Roger, Ryan Greenblatt et al. (2023)
- **Become a Person Who Actually Does Things** by Neel Nanda (2022)
- **Working in AI Alignment** by Charlie Rogers-Smith (2024)
 
### Governance

- **Being the (Pareto) Best in the World** by John Wentworth (2019)
- **Markets Have Overestimated AI-Driven Productivity Gains, Says MIT Economist** by Daron Acemoglu (2024)
- **How Will AI Affect Productivity?** by Martin Neil Baily and Aidan T. Kane (2024)
- **The Transformative Potential of AGI – and When It Might Arrive** by Shane Legg and Chris Anderson (2023)
- **Future Risks of Frontier AI** by The UK Government Office for Science (2023)
- **An Overview of Catastrophic AI Risks** by Dan Hendrycks, Mantas Mazeika, and Thomas Woodside (2023)
- **Survey of 2,778 AI Authors: Six Parts in Pictures** by Katja Grace
- **Strengthening Resilience to AI Risk: A Guide for UK Policymakers** by Ardi Janjeva, Nikhil Mulani, Rosamund Powell, Jess Whittlestone, and Shahar Avin (2023)
- **The Policy Playbook: Building a Systems-Oriented Approach to Technology and National Security Policy** by Jack Corrigan, Melissa Flagg, and Dewi Murdick (2023)
- **Historical Case Studies of Technology Governance and International Agreements** by BlueDot Impact (2023)
- **AI Index Report 2024, Chapter 7: Policy and Governance** by Nestor Maslej et al. (2024)
- **Recent U.S. Efforts on AI Policy** by The US Cybersecurity and Infrastructure Security Agency (2024)
- **FACT SHEET: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence** by The White House (2023)
- **High-Level Summary of the AI Act** by The Future of Life Institute (2024)
- **China’s AI Regulations and How They Get Made** by Matt Sheehan (2023)
- **A Pro-Innovation Approach to AI Regulation** by UK Department of Science, Technology, and Innovation (2024)
- **The Bletchley Declaration** by Countries Attending the AI Safety Summit, 1-2 November 2023** by UK Government (2023)
- **Key Facts: UNESCO’s Recommendation on the Ethics of Artificial Intelligence** by The United Nations Educational, Scientific, and Cultural Organization (2023)
- **OECD AI Principles** by The Organization for Economic Cooperation and Development (2024)
- **Primer on AI Chips and AI Governance** by BlueDot Impact (2023)
- **Model Evaluation for Extreme Risks** by Toby Shevlane (2023)
- **International Institutions for Advanced AI** by Lewis Ho, Joslyn Barnhart, and Robert Trager et al. (2023)
- **Primer on Safety Standards and Regulations for Industrial-Scale AI Development** by BlueDot Impact (2023)
- **Societal Adaptation to Advanced AI** by Jamie Bernardi, Gabriel Mukobi, Hilary Greaves, Lennart Heim, and Markus Anderljung (2024)
- **Managing Extreme AI Risks Amid Rapid Progress** by Yoshua Bengio et al. (2023)
- **If-Then Commitments for AI Risk Reduction** by Holden Karnofsky (2024)
- **Responsible Artificial Intelligence Efforts in the Global South** by Giulia Neaher (2024)
- **Considerations for Governing Open Foundation Models** by Rishi Bommasani et al. (2023)
- **Open-Sourcing Highly Capable Foundation Models: An Evaluation of Risks, Benefits, and Alternative Methods for Pursuing Open-Source Objectives** by Elizabeth Seger et al. (2023)
- **Career Profile: AI Governance and Policy** by 80000 Hours (2024)
 
### Biosecurity

- **The Increasing Threat of Biological Weapons: Handle with Sufficient and Proportionate Care** by Erik Frinking, Paul Sinning, Eva Bontje, Christopher Frattina della Frattina, and Mercedes Abdalla
- **Who Should We Fear More: Biohackers, Disgruntled Postdocs, or Bad Governments? A Simple Risk Chain Model of Biorisk** by Anders Sandberg and Cassidy Nelson
- **Artificial Intelligence and Biological Misuse: Differentiating Risks of Language Models and Biological Design Tools** by Jonas B. Sandbrink
<!-- - **Highly Accurate Protein Structure Prediction with AlphaFold** in Nature -->
<!-- - This is How AI Will Transform How Science Gets Done -->

### Additional Resources

- **Artificial Intelligence: A Modern Approach** by S. J. Russell and P. Norvig
- **Universal Intelligence: A Definition of Machine Intelligence** by S. Legg and M. Hutter
- **Computing Machinery and Intelligence** by A. M. Turing
- **The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain** by F. Rosenblatt
- **Deep Blue** by M. Campbell, A. J. Hoane Jr, and F. Hsu
- **Probabilistic Graphical Models: Principles and Techniques** by D. Koller and N. Friedman
- **Random Forests** by L. Breiman
- **Greedy Function Approximation: A Gradient Boosting Machine** by J. H. Friedman
- **Support-Vector Networks** by C. Cortes and V. Vapnik
- **ImageNet: A Large-Scale Hierarchical Image Database** by J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei
- **ImageNet Classification with Deep Convolutional Neural Networks** by A. Krizhevsky, I. Sutskever, and G. E. Hinton
- **Mastering the Game of Go with Deep Neural Networks and Tree Search** by D. Silver et al.
- **Language Models Are Unsupervised Multitask Learners** by A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever
- **Superintelligence: Paths, Dangers, Strategies** by N. Bostrom
- **Pattern Recognition and Machine Learning** by C. M. Bishop
- **Probabilistic Machine Learning: An Introduction** by K. P. Murphy
- **Classification vs Regression** by A. Drouin and F. Laviolette
- **Probability of Passing Exam Versus Hours Studying** by Canley
- **A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks** by D. Hendrycks and K. Gimpel
- **Anomaly and Out-of-Distribution Detection** by D. Hendrycks
- **Precision Recall** by Walber
- **ROC Curve** by cmglee and M. Thoma
- **Semantic Residual Pyramid Network for Image Inpainting** by Haiyin Luo and Yuhui Zheng
- **The Bitter Lesson** by R. Sutton. 
- **AI and Compute** by D. Amodei, D. Hernandez, G. Sastry, J. Clark, G. Brockman, and I. Sutskever (2018)
- **Dual Use of Artificial-Intelligence-Powered Drug Discovery** by F. L. Urbina, F. Lentzos, C. Invernizzi, and S. Ekins, Nature Machine Intelligence (2022)
- **Key Trends and Figures in Machine Learning** by Epoch (2023). 
- **The $150m Machine Keeping Moore's Law Alive (2021). Available: Wired
- **ETO Supply Chain Explorer** by Z. Arnold, J. VerWey, J. Melot, and N. Signh.
- **The Semiconductor Supply Chain: Assessing National Competitiveness** by S. M. Khan, A. Mann, and D. Peterson, Center for Security and Emerging Technology, vol. 8, no. 8 (2021)

