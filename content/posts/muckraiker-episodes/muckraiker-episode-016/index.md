---
url: /muckraikers/e016/
title: 'The Co-opting of "Safety"'
summary: 'How "safety" has been misappropriated by developers to justify reckless deployment while avoiding real safety.'
date: 2025-08-20
lastmod: 2025-08-20

image:
  caption: 'muckrAIkers Cover Art'
  preview_only: true
  filename: muckraikers_cover-art.jpg

authors:
  - muckraikers

tags:
  - Narratives & Hype
  - Current Harms

categories:
  - Podcast
---

<div style="text-align: justify">
We dig into how the concept of AI "safety" has been co-opted and weaponized by tech companies. Starting with examples like Mecha-Hitler Grok, we explore how real safety engineering differs from AI "alignment," the myth of the alignment tax, and why this semantic confusion matters for actual safety.

{{< transistor src="https://share.transistor.fm/e/08948e9d" >}}
<div style="font-size: x-small;font-style: italic;padding-left: 2.25rem;">EPISODE RECORDED 2025.08.05</div>
</div>


## Chapters

<div style="text-align: left; font-family:monospace;">
00:00:00 ❙ Intro<br>
00:00:21 ❙ Mecha-Hitler Grok<br>
00:10:07 ❙ "Safety"<br>
00:19:40 ❙ Under-specification<br>
00:53:56 ❙ This time isn't different<br>
01:01:46 ❙ Alignment Tax myth<br>
01:17:37 ❙ Actually making AI safer
</div>

## Links
- JMLR [article](https://www.jmlr.org/papers/v23/20-1335.html) - Underspecification Presents Challenges for Credibility in Modern Machine Learning
- Trail of Bits [paper](https://github.com/trailofbits/publications/blob/master/papers/toward_comprehensive_risk_assessments.pdf) - Towards Comprehensive Risk Assessments and Assurance of AI-Based Systems
- SSRN [paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4924942) - Uniqueness Bias: Why It Matters, How to Curb It

### Additional Referenced Papers
- NeurIPS [paper](https://www.safetywashing.ai) - Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?
- ICML [paper](https://arxiv.org/abs/2312.06942) - AI Control: Improving Safety Despite Intentional Subversion
- ICML [paper](https://darkbench.ai) - DarkBench: Benchmarking Dark Patterns in Large Language Models
- OSF [preprint](https://osf.io/preprints/osf/ygx5q_v1) - Current Real-World Use of Large Language Models for Mental Health
- Anthropic [preprint](https://arxiv.org/pdf/2204.05862) - Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback

### Inciting Examples
- ars Technica [article](https://arstechnica.com/tech-policy/2025/08/us-government-agency-drops-grok-after-mechahitler-backlash-report-says/) - US government agency drops Grok after MechaHitler backlash, report says
- The Guardian [article](https://www.theguardian.com/technology/2025/may/14/elon-musk-grok-white-genocide) - Musk’s AI Grok bot rants about ‘white genocide’ in South Africa in unrelated chats
- BBC [article](https://www.bbc.com/news/articles/cn4jnwdvg9qo) - Update that made ChatGPT 'dangerously' sycophantic pulled

### Other Sources
- London Daily [article](https://londondaily.com/uk-ai-safety-institute-rebrands-as-ai-security-institute-to-focus-on-crime-and-national-security) - UK AI Safety Institute Rebrands as AI Security Institute to Focus on Crime and National Security
- Vice [article](https://www.vice.com/en/article/prominent-ai-philosopher-and-father-of-longtermism-sent-very-racist-email-to-a-90s-philosophy-listserv/) - Prominent AI Philosopher and ‘Father’ of Longtermism Sent Very Racist Email to a 90s Philosophy Listserv
- LessWrong [blogpost](https://www.lesswrong.com/posts/jMzBhCRrr7otmqcvK/notkilleveryoneism-sounds-dumb) - "notkilleveryoneism" sounds dumb (see comments)
- EA Forum [blogpost](https://forum.effectivealtruism.org/posts/XdhwXppfqrpPL2YDX/an-overview-of-the-ai-safety-funding-situation) - An Overview of the AI Safety Funding Situation
- [Book](https://link.springer.com/book/10.1007/978-3-319-24301-6) by Dmitry Chernov and Didier Sornette - Man-made Catastrophes and Risk Information Concealment
- Euronews [article](https://www.euronews.com/next/2025/08/05/openai-adds-mental-health-safeguards-to-chatgpt-saying-chatbot-has-fed-into-users-delusion) - OpenAI adds mental health safeguards to ChatGPT, saying chatbot has fed into users’ ‘delusions’
- Pleias [website](https://pleias.fr/)
- Wikipedia [page](https://en.wikipedia.org/wiki/Jaywalking) on Jaywalking
