---
url: /muckraikers/e017/
title: AI Safety for Who?
summary: "AI safety is making you less safe: chatbot anthropomorphization, mental health harms, dark patterns"
date: 2025-10-13
lastmod: 2025-10-13

image:
  caption: 'muckrAIkers Cover Art'
  preview_only: true
  filename: muckraikers_cover-art.jpg

authors:
  - muckraikers

tags:
  - Narratives & Hype
  - Current Harms

categories:
  - Podcast
---

<div style="text-align: justify">

Jacob and Igor argue that AI safety is hurting users, not helping them. The techniques used to make chatbots "safe" and "aligned," such as instruction tuning and RLHF, anthropomorphize AI systems such they take advantage of our instincts as social beings. At the same time, Big Tech companies push these systems for "wellness" while dodging healthcare liability, causing real harms *today*. We discuss what actual safety would look like, drawing on self-driving car regulations.

{{< transistor src="https://share.transistor.fm/e/222dc32a" >}}
<div style="font-size: x-small;font-style: italic;padding-left: 2.25rem;">EPISODE RECORDED 2025.09.28; <a href="https://share.transistor.fm/s/222dc32a/transcript.txt" target="_blank" rel="noreferrer noopener">TRANSCRIPT</a></a></div>
</div>


## Chapters

<div style="text-align: left; font-family:monospace;">
00:00 ❙ Introduction & AI Investment Insanity<br>
01:43 ❙ The Problem with AI Safety<br>
08:16 ❙ Anthropomorphizing AI & Its Dangers<br>
26:55 ❙ Mental Health, Wellness, and AI<br>
39:15 ❙ Censorship, Bias, and Dual Use<br>
44:42 ❙ Solutions, Community Action & Final Thoughts
</div>

## Links

### AI Ethics & Philosophy
-   Foreign affairs [article](https://archive.ph/lbek5) - The Cost of the AGI Delusion
-   Nature [article](https://www.nature.com/articles/s42256-019-0114-4) - Principles alone cannot guarantee ethical AI
-   Xeiaso [blog post](https://xeiaso.net/blog/2025/who-assistant-serve/) - Who Do Assistants Serve?
-   Argmin [article](https://www.argmin.net/p/the-banal-evil-of-ai-safety) - The Banal Evil of AI Safety
-   AI Panic News [article](https://www.aipanic.news/p/the-rationality-trap) - The Rationality Trap

### AI Model Bias, Failures, and Impacts
-   BBC [news article](https://www.bbc.com/news/technology-33347866) - AI Image Generation Issues
-   The New York Times [article](https://www.nytimes.com/2024/02/22/technology/google-gemini-german-uniforms.html) - Google Gemini German Uniforms Controversy
-   The Verge [article](https://www.theverge.com/2024/2/23/24081309/google-gemini-embarrassing-ai-pictures-diverse-nazi) - Google Gemini's Embarrassing AI Pictures
-   NPR [article](https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content) - Grok, Elon Musk, and Antisemitic/Racist Content
-   AccelerAId [blog post](https://acceleraid.ai/en/about/blog/how-ai-nudges-are-transforming-up-and-cross-selling-2/) - How AI Nudges are Transforming Up-and Cross-Selling
-   AI Took My Job [website](https://www.aitookmyjob.io/)

### AI Mental Health & Safety Concerns
-   Euronews [article](https://www.euronews.com/next/2023/03/31/man-ends-his-life-after-an-ai-chatbot-encouraged-him-to-sacrifice-himself-to-stop-climate-) - AI Chatbot Tragedy
-   Popular Mechanics [article](https://www.popularmechanics.com/technology/robots/a65781776/openai-psychosis/) - OpenAI and Psychosis
-   Psychology Today [article](https://www.psychologytoday.com/us/blog/urban-survival/202507/the-emerging-problem-of-ai-psychosis) - The Emerging Problem of AI Psychosis
-   Rolling Stone [article](https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/) - AI Spiritual Delusions Destroying Human Relationships
-   The New York Times [article](https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html) - AI Chatbots and Delusions

### Guidelines, Governance, and Censorship
-   [Preprint](https://arxiv.org/abs/2505.12625) - R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model
-   Minds & Machines [article](https://link.springer.com/article/10.1007/S11023-020-09517-8) - The Ethics of AI Ethics: An Evaluation of Guidelines
-   SSRN [paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5283275) - Instrument Choice in AI Governance
-   Anthropic [announcement](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers) - Claude Gov Models for U.S. National Security Customers
-   Anthropic [documentation](https://www.anthropic.com/news/claudes-constitution) - Claude's Constitution
-   Reuters [investigation](https://www.reuters.com/investigates/special-report/meta-ai-chatbot-guidelines/) - Meta AI Chatbot Guidelines
-   Swiss Federal Council [consultation](https://www.fedlex.admin.ch/de/consultation-procedures?news_period=last_day&news_pageNb=1&news_order=desc&news_itemsPerPage=10) - Swiss AI Consultation Procedures
-   Grok Prompts Github [Repo](https://x.com/xai/status/1923183622422458851)
-   Simon Willison [blog post](https://simonwillison.net/2025/Jul/12/grok-4-heavy/) - Grok 4 Heavy
