---
url: /muckraikers/e015/
title: Reasoning v2
summary: 
date: 2025-07-13
lastmod: 2025-07-13

_build:
  render: never
  list: never
cascade:
  _build:
    render: never
    list: never

image:
  caption: 'muckrAIkers Cover Art'
  preview_only: true
  filename: muckraikers_cover-art.jpg

authors:
  - muckraikers

tags:
  - Reasoning
  - Agents

categories: 
  - Podcast
---

<div style="text-align: justify">
In this episode, we provide a critical, evidence-based update on what reasoning models could be doing. Words do indeed matter; we suggest that reasoning language models should be perceived as rambling models since do not develop reasoning in the classical sense i.e "drawing conclusions from facts using logical inference" but rather ... + potempkin  


{{< transistor src="" >}}
<div style="font-size: x-small;font-style: italic;padding-left: 2.25rem;">EPISODE RECORDED 2025.XX.XX; <a href="" target="_blank" rel="noreferrer noopener">TRANSCRIPT</a></a></div>
</div>


## Chapters
<div style="text-align: left; font-family:monospace;">
00:00:28 ❙ OBB follow-up and Zack's talent poaching<br>
03:09:03 ❙ Reasoning vs ranbling language models<br>
06:48:00 ❙ Distinguishing Classical Reasoning from AI Reasoning<br>
08:40 ❙ The Importance of Definitions in AI<br>
10:24 ❙ Implications of AI Reasoning in High-Risk Domains<br>
11:45 ❙ The Evolution of Large Rambling Models<br>
13:52 ❙ Understanding the Rambling Process<br>
14:54 ❙ Critiques of AI Reasoning Models<br>
15:32 ❙ The Potemkin Understanding in AI<br>
17:17 ❙ Evaluating AI Performance and Benchmarks<br>
18:47 ❙ The Future of AI Reasoning and Rambling Models
Outro
</div>

## Links
- Apple [paper](http://arxiv.org/abs/2506.06941) - The Illusion of Thinking
- ICML 2025 [paper] (https://arxiv.org/abs/2506.21521) - Potemkin Understanding in Large Language Models
- [Preprint](https://arxiv.org/abs/2407.21787) - Large Language Monkeys: Scaling Inference Compute with Repeated Sampling


### Theoretical understanding
- Max M. Schlereth  [Manuscript] (https://philarchive.org/rec/SCHAIM-14) - The limits of AGI part II
- [Preprint](https://arxiv.org/html/2504.09762v1) - (How) Do Reasoning Models Reason?
- [Preprint](http://arxiv.org/abs/2503.03961) - A Little Depth Goes a Long Way: The Expressive Power of Log-Depth Transformers
- NeurIPS 2024 [paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/3107e4bdb658c79053d7ef59cbc804dd-Abstract-Conference.html) - How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad


### Empirical explanations
- [Preprint](https://arxiv.org/abs/2502.17578) - How Do Large Language Monkeys Get Their Power (Laws)?
- Andon Labs [Preprint](http://arxiv.org/abs/2502.15840) - Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents
- LeapLab, Tsinghua University and Shanghai Jiao Tong University [paper](http://arxiv.org/abs/2504.13837) - Does Reinforcement Learning Really Incentivize Reasoning Capacity
- [Preprint](https://arxiv.org/abs/2505.13697) - RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs
- [Preprint](https://arxiv.org/abs/2505.18623) - Mind The Gap: Deep Learning Doesn't Learn Deeply
- [Preprint](https://arxiv.org/abs/2503.14499) - Measuring AI Ability to Complete Long Tasks
- [Preprint](https://arxiv.org/abs/2410.05229) - GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models


### Other Sources
- Zuck's Haul [webpage](https://zuckshaul.com/) - Meta's talent acquisition tracker
    - Hacker News [discussion](https://news.ycombinator.com/item?id=44477512) - Opinions from the AI community 
- Interconnects [blogpost](https://www.interconnects.ai/p/the-rise-of-reasoning-machines) - The rise of reasoning machines
- Anthropic [blog](https://www.anthropic.com/research/project-vend-1) - Project Vend: Can Claude run a small shop?