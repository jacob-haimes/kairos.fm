---
url: /muckraikers/e010/
title: NeurIPS 2024 Wrapped üåØ
summary: The largest conference in machine learning had over 15,000 people in attendance, and so much tea!
date: 2024-12-30
 

image:
  caption: 'muckrAIkers Temporary Cover Art'
  preview_only: true
  filename: muckraikers_cover-art.jpg

authors:
  - muckraikers

tags:
  - Machine Learning
  - Conference

categories: 
  - Podcast
---

<div style="text-align: justify">
What happens when you bring over 15,000 machine learning nerds to one city? If your guess didn't include racism, sabotage and scandal, belated epiphanies, a spicy SoLaR panel, and many fantastic research papers, you wouldn't have captured my experience. In this episode we discuss the drama and takeaways from NeurIPS 2024.


{{< transistor src="https://share.transistor.fm/e/5075e6ee" >}}
<div style="font-size: x-small;font-style: italic;padding-left: 2.25rem;">EPISODE RECORDED 2024.12.22</a></div>
</div>


## Gallery

{{< multi-image-quickview folder="neurips-24" >}}

## Chapters

<div style="text-align: left; font-family:monospace;">
00:00:00 ‚ùô Recording date<br>
00:00:05 ‚ùô Intro<br>
00:00:44 ‚ùô Obligatory mentions<br>
00:01:54 ‚ùô SoLaR panel<br>
00:18:43 ‚ùô Test of Time<br>
00:24:17 ‚ùô And now: science!<br>
00:28:53 ‚ùô Downsides of benchmarks<br>
00:41:39 ‚ùô Improving the science of ML<br>
00:53:07 ‚ùô Performativity<br>
00:57:33 ‚ùô NopenAI and Nanthropic<br>
01:09:35 ‚ùô Fun/interesting papers<br>
01:13:12 ‚ùô Initial takes on o3<br>
01:18:12 ‚ùô WorkArena<br>
01:25:00 ‚ùô Outro
</div>

## Links

<div style="text-align: justify">

_Note: many workshop papers had not yet been published to arXiv as of preparing this episode, the OpenReview submission page is provided in these cases._

</div>

- NeurIPS [statement](https://neurips.cc/Conferences/2024/StatementOnInclusivity) on inclusivity
- CTOL Digital Solutions [article](https://www.ctol.digital/news/neurips-2024-controversy-mit-professor-remarks-chinese-researchers-triumphs/) - NeurIPS 2024 Sparks Controversy: MIT Professor's Remarks Ignite "Racism" Backlash Amid Chinese Researchers‚Äô Triumphs
- (1/2) NeurIPS Best [Paper](https://arxiv.org/abs/2404.02905) - Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction
- Visual Autoregressive Model [report](https://var-integrity-report.github.io) *this link now provides a 404 error*
  - Don't worry, here it is on [archive.is](https://archive.is/5GklT)
- Reuters [article](https://www.reuters.com/technology/artificial-intelligence/bytedance-seeks-11-mln-damages-intern-ai-breach-case-report-says-2024-11-28/) - ByteDance seeks $1.1 mln damages from intern in AI breach case, report says
- CTOL Digital Solutions [article](https://www.ctol.digital/news/ai-genius-neurips-win-bytedance-legal-battle/) - NeurIPS Award Winner Entangled in ByteDance's AI Sabotage Accusations: The Two Tales of an AI Genius
- Reddit post on Ilya's [talk](https://www.reddit.com/r/singularity/comments/1hdrjvq/ilyas_full_talk_at_neurips_2024_pretraining_as_we/)
- SoLaR workshop [page](https://solar-neurips.github.io)

## Referenced Sources
- Harvard Data Science Review [article](https://hdsr.mitpress.mit.edu/pub/g9mau4m0/release/2) - Data Science at the Singularity
- [Paper](https://arxiv.org/abs/2204.10817) - Reward Reports for Reinforcement Learning
- [Paper](https://arxiv.org/abs/2002.09398) - It's Not What Machines Can Learn, It's What We Cannot Teach 
- [Paper](https://arxiv.org/abs/2003.12206) - NeurIPS Reproducibility Program
- [Paper](https://arxiv.org/abs/2003.08505) - A Metric Learning Reality Check

### Improving Datasets, Benchmarks, and Measurements
- Tutorial [video](https://neurips.cc/virtual/2024/tutorial/99528) + [slides](https://neurips.cc/media/neurips-2024/Slides/99528_aXgzqdX.pdf) - Experimental Design and Analysis for AI Researchers (note: I think you need to have attended NeurIPS to access the recording)
- [Paper](https://betterbench.stanford.edu) - BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices
- [Paper](https://www.safetywashing.ai) - Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?
- [Paper](https://arxiv.org/abs/2411.00266) - A Systematic Review of NeurIPS Dataset Management Practices
- [Paper](https://arxiv.org/abs/2410.22473) - The State of Data Curation at NeurIPS: An Assessment of Dataset Development Practices in the Datasets and Benchmarks Track
- [Paper](https://arxiv.org/abs/2410.24100) - Benchmark Repositories for Better Benchmarking
- [Paper](https://research.google/blog/croissant-a-metadata-format-for-ml-ready-datasets/) - Croissant: A Metadata Format for ML-Ready Datasets
- [Paper](https://arxiv.org/abs/2406.09867) - Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox
- [Paper](https://arxiv.org/abs/2411.10939) - Evaluating Generative AI Systems is a Social Science Measurement Challenge
- [Paper](https://arxiv.org/abs/2409.00844) - Report Cards: Qualitative Evaluation of LLMs

### Governance Related
- [Paper](https://arxiv.org/abs/2412.03824) - Towards Data Governance of Frontier AI Models
- [Paper](https://openreview.net/forum?id=St6azqVuqs) - Ways Forward for Global AI Benefit Sharing
- [Paper](https://arxiv.org/abs/2410.02230) - How do we warn downstream model providers of upstream risks?
  - Unified Model Records [tool](https://modelrecord.com)
- [Paper](https://openreview.net/forum?id=OeT2vCFqYY) - Policy Dreamer: Diverse Public Policy Creation via Elicitation and Simulation of Human Preferences
- [Paper](https://arxiv.org/abs/2409.14055) - Monitoring Human Dependence on AI Systems with Reliance Drills
- [Paper](https://arxiv.org/abs/2411.19211) - On the Ethical Considerations of Generative Agents
- [Paper](https://openreview.net/forum?id=OvGYbqOEki) - GPAI Evaluation Standards Taskforce: Towards Effective AI Governance
- [Paper](https://openreview.net/forum?id=EH6SmoChx9) - Levels of Autonomy: Liability in the age of AI Agents

### Certified Bangers + Useful Tools
- [Paper](https://arxiv.org/abs/2402.07712) - Model Collapse Demystified: The Case of Regression
- [Paper](https://arxiv.org/abs/2405.19534) - Preference Learning Algorithms Do Not Learn Preference Rankings
- LLM Dataset Inference [paper](https://arxiv.org/abs/2406.06443) + [repo](https://github.com/pratyushmaini/llm_dataset_inference/)
- dattri [paper](https://arxiv.org/abs/2410.04555) + [repo](https://github.com/TRAIS-Lab/dattri)
- DeTikZify [paper](https://arxiv.org/abs/2405.15306) + [repo](https://github.com/potamides/DeTikZify)

### Fun Benchmarks/Datasets
- Paloma [paper](https://arxiv.org/abs/2312.10523) + [dataset](https://huggingface.co/datasets/allenai/paloma)
- RedPajama [paper](https://arxiv.org/abs/2411.12372) + [dataset](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)
- Assemblage [webpage](https://assemblage-dataset.net)
- WikiDBs [webpage](https://wikidbs.github.io)
- WhodunitBench [repo](https://github.com/jun0wanan/WhodunitBench-Murder_Mystery_Games)
- ApeBench [paper](https://arxiv.org/abs/2411.00180) + [repo](https://github.com/tum-pbs/apebench)
- WorkArena++ [paper](https://arxiv.org/abs/2407.05291)

### Other Sources
- [Paper](https://arxiv.org/abs/2412.07066) - The Mirage of Artificial Intelligence Terms of Use Restrictions
- [Paper](https://dl.acm.org/doi/abs/10.1145/3630106.3658929?casa_token=yIEkPHNWMQcAAAAA:tlzV9xzpsfdHbNpM6ZV-2rF4yFidBABwHz2E5uMt4ez-OSnF3xHu97eJQNkZWaKGV7QIzFh03-F0dRSn) relating to performativity - Algorithmic Fairness in Performative Policy Learning: Escaping the Impossibility of Group Fairness
- Jacob Buckman [article](https://jacobbuckman.com/2021-05-29-please-commit-more-blatant-academic-fraud/) - Please Commit More Blatant Academic Fraud
- Centre for Future Generations [brief](https://cfg.eu/the-ai-safety-institute-network-who-what-and-how/) - The AI Safety Institute Network
- Margaret Mitchell's [website](https://www.m-mitchell.com)
- [BlueSky](https://bsky.app)